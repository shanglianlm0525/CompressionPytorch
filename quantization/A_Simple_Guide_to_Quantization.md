# A Simple Guide to Quantization

**Quantization**: Quantization refers to techniques for performing computations and storing tensors at lower bitwidths than floating point precision.


## Post Training Quantization

- (**TensorRT int8**) 8-bit Inference with TensorRT [[Paper\]](https://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf)

- (**Google Whitepaper**) Quantizing deep convolutional networks for efficient inference: A whitepaper [[Paper\]](https://arxiv.org/pdf/1806.08342.pdf)

- (**EasyQuant**) EasyQuant: Post-training Quantization via Scale Optimization [[Paper\]](https://arxiv.org/pdf/2006.16669.pdf)

- (**DFQ**) Data-Free Quantization Through Weight Equalization and Bias Correction [[Paper\]](https://arxiv.org/pdf/1906.04721.pdf)





## Quantization Aware Training








## REFERENCES

